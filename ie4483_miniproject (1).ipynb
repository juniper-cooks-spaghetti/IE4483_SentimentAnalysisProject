{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             reviews  sentiments\n",
      "0  I bought this belt for my daughter in-law for ...           1\n",
      "1  The size was perfect and so was the color.  It...           1\n",
      "2  Fits and feels good, esp. for doing a swim rac...           1\n",
      "3  These socks are absolutely the best. I take pi...           1\n",
      "4  Thank you so much for the speedy delivery they...           1\n",
      "                                             reviews\n",
      "0  I bought 2 sleepers.  sleeper had holes in the...\n",
      "1  I dare say these are just about the sexiest th...\n",
      "2  everything about the transaction (price, deliv...\n",
      "3  Not bad for just a shirt.  Very durable, and m...\n",
      "4  These are truly wrinkle free and longer than t...\n"
     ]
    }
   ],
   "source": [
    "#Changed the 'train_data' into 'raw_data' and changed 'test_data' into 'answer_data'\n",
    "\n",
    "raw_data = pd.read_json('train.json')\n",
    "answer_data = pd.read_json('test.json')\n",
    "\n",
    "print(raw_data.head())\n",
    "print(answer_data.head())\n",
    "\n",
    "raw_labels = raw_data['sentiments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove stop words\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    # Remove extra whitespaces\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['cleaned_reviews'] = raw_data['reviews'].apply(clean_text)\n",
    "answer_data['cleaned_reviews'] = answer_data['reviews'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             reviews  sentiments  \\\n",
      "0  I bought this belt for my daughter in-law for ...           1   \n",
      "1  The size was perfect and so was the color.  It...           1   \n",
      "2  Fits and feels good, esp. for doing a swim rac...           1   \n",
      "3  These socks are absolutely the best. I take pi...           1   \n",
      "4  Thank you so much for the speedy delivery they...           1   \n",
      "\n",
      "                                     cleaned_reviews  \n",
      "0         bought belt daughter inlaw christmas loved  \n",
      "1            size perfect color looked like web page  \n",
      "2  fits feels good esp swim race highly recommend...  \n",
      "3  socks absolutely best take pilates classes hot...  \n",
      "4  thank much speedy delivery came time rehearsal...  \n"
     ]
    }
   ],
   "source": [
    "print(raw_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train padded shape: (7401, 518)\n",
      "Test padded shape: (1851, 518)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Tokenization: Basically divides the sentences into segments\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(raw_data['cleaned_reviews']) #Indexes each token (each word is given a number). Index = 0 is for padding\n",
    "\n",
    "# Convert text to sequences\n",
    "raw_sequences = tokenizer.texts_to_sequences(raw_data['cleaned_reviews'])\n",
    "answer_sequences = tokenizer.texts_to_sequences(answer_data['cleaned_reviews'])\n",
    "\n",
    "# Padding sequences\n",
    "max_length = max(max(len(seq) for seq in raw_sequences), max(len(seq) for seq in answer_sequences)) #Finding the maximum sequence length from both the raw_data and answer_data\n",
    "raw_final = pad_sequences(raw_sequences, maxlen=max_length, padding='post') #standardize the array\n",
    "answer_final = pad_sequences(answer_sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# Display the shape of padded sequences\n",
    "print(f'Train padded shape: {raw_final.shape}')\n",
    "print(f'Test padded shape: {answer_final.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  12,  288,  214, ...,    0,    0,    0],\n",
       "       [   5,   39,   41, ...,    0,    0,    0],\n",
       "       [  86,  323,    7, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [1309,  401,  217, ...,    0,    0,    0],\n",
       "       [ 143,  957,  380, ...,    0,    0,    0],\n",
       "       [ 230,  906,   97, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  12,  116, 7406, ...,    0,    0,    0],\n",
       "       [3212,  123, 5234, ...,    0,    0,    0],\n",
       "       [ 172, 1543,   18, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [  15,  108,  211, ...,    0,    0,    0],\n",
       "       [ 214,  132,   53, ...,    0,    0,    0],\n",
       "       [3179,  917,  153, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors from GloVe.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load GloVe word embeddings (download and extract glove.6B.100d.txt)\n",
    "embedding_dim = 100 #as vectors of n real numbers\n",
    "glove_file = 'C:/Users/User/Downloads/Telegram Desktop/glove.6B/glove.6B.100d.txt' #change this to your glove path\n",
    "embeddings_index = {}\n",
    "\n",
    "with open(glove_file, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(f'Loaded {len(embeddings_index)} word vectors from GloVe.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (16366, 100)\n"
     ]
    }
   ],
   "source": [
    "# Prepare the embedding matrix\n",
    "vocab_size = len(tokenizer.word_index) + 1  # +1 for padding token\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "# Map the words in the tokenizer's vocabulary to GloVe vectors\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector  # Words found in GloVe will use pretrained vectors\n",
    "\n",
    "# Check the embedding matrix shape\n",
    "print(f'Embedding matrix shape: {embedding_matrix.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "518"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split the raw data\n",
    "from sklearn.model_selection import train_test_split\n",
    "raw_train, raw_test, label_train, label_test = train_test_split(\n",
    "    raw_final, raw_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 518, 100)          1636600   \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 256)              234496    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,871,353\n",
      "Trainable params: 1,871,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "19/19 [==============================] - 6s 325ms/step - loss: 0.4706 - acc: 0.8003 - val_loss: 0.3773 - val_acc: 0.8682\n",
      "Epoch 2/20\n",
      "19/19 [==============================] - 6s 326ms/step - loss: 0.3889 - acc: 0.8486 - val_loss: 0.3358 - val_acc: 0.8691\n",
      "Epoch 3/20\n",
      "19/19 [==============================] - 6s 325ms/step - loss: 0.3161 - acc: 0.8604 - val_loss: 0.2853 - val_acc: 0.8843\n",
      "Epoch 4/20\n",
      "19/19 [==============================] - 6s 322ms/step - loss: 0.2483 - acc: 0.9003 - val_loss: 0.2470 - val_acc: 0.8995\n",
      "Epoch 5/20\n",
      "19/19 [==============================] - 6s 330ms/step - loss: 0.1920 - acc: 0.9267 - val_loss: 0.2418 - val_acc: 0.9037\n",
      "Epoch 6/20\n",
      "19/19 [==============================] - 6s 323ms/step - loss: 0.1578 - acc: 0.9405 - val_loss: 0.2365 - val_acc: 0.9037\n",
      "Epoch 7/20\n",
      "19/19 [==============================] - 6s 324ms/step - loss: 0.1155 - acc: 0.9611 - val_loss: 0.2535 - val_acc: 0.9122\n",
      "Epoch 8/20\n",
      "19/19 [==============================] - 6s 322ms/step - loss: 0.0862 - acc: 0.9732 - val_loss: 0.2889 - val_acc: 0.8970\n",
      "Epoch 9/20\n",
      "19/19 [==============================] - 6s 316ms/step - loss: 0.0744 - acc: 0.9761 - val_loss: 0.3029 - val_acc: 0.9046\n",
      "Epoch 10/20\n",
      "19/19 [==============================] - 6s 316ms/step - loss: 0.0836 - acc: 0.9751 - val_loss: 0.3309 - val_acc: 0.8936\n",
      "Epoch 11/20\n",
      "19/19 [==============================] - 6s 320ms/step - loss: 0.0669 - acc: 0.9823 - val_loss: 0.2663 - val_acc: 0.9054\n",
      "Epoch 12/20\n",
      "19/19 [==============================] - 6s 313ms/step - loss: 0.0427 - acc: 0.9884 - val_loss: 0.3304 - val_acc: 0.8936\n",
      "Epoch 13/20\n",
      "19/19 [==============================] - 6s 318ms/step - loss: 0.0331 - acc: 0.9932 - val_loss: 0.4004 - val_acc: 0.9020\n",
      "Epoch 14/20\n",
      "19/19 [==============================] - 6s 329ms/step - loss: 0.0246 - acc: 0.9945 - val_loss: 0.3461 - val_acc: 0.9113\n",
      "Epoch 15/20\n",
      "19/19 [==============================] - 6s 312ms/step - loss: 0.0235 - acc: 0.9951 - val_loss: 0.3879 - val_acc: 0.8919\n",
      "Epoch 16/20\n",
      "19/19 [==============================] - 6s 311ms/step - loss: 0.0253 - acc: 0.9945 - val_loss: 0.3309 - val_acc: 0.9139\n",
      "Epoch 17/20\n",
      "19/19 [==============================] - 6s 309ms/step - loss: 0.0557 - acc: 0.9854 - val_loss: 0.2801 - val_acc: 0.9054\n",
      "Epoch 18/20\n",
      "19/19 [==============================] - 6s 311ms/step - loss: 0.0420 - acc: 0.9888 - val_loss: 0.3553 - val_acc: 0.9105\n",
      "Epoch 19/20\n",
      "19/19 [==============================] - 6s 308ms/step - loss: 0.0166 - acc: 0.9968 - val_loss: 0.3467 - val_acc: 0.9122\n",
      "Epoch 20/20\n",
      "19/19 [==============================] - 6s 310ms/step - loss: 0.0106 - acc: 0.9987 - val_loss: 0.4208 - val_acc: 0.9062\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Bidirectional\n",
    "\n",
    "\n",
    "# Define your model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=max_length, trainable=True))\n",
    "#CuDNN has very strict requirements to be able to use GPU, im putting it here to show the requirements, some of them are already default settings though\n",
    "model.add(Bidirectional(LSTM(128,\n",
    "                             activation='tanh',  # Default settings, to show\n",
    "                             recurrent_activation='sigmoid',  # Default\n",
    "                             return_sequences=False,  # Set appropriately, not Default\n",
    "                             recurrent_dropout=0,  # Must be 0 for cuDNN\n",
    "                             unroll=False,  # Must be False for cuDNN\n",
    "                             use_bias=True)))  # Default is True\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "snn_model_history = model.fit(raw_train, label_train, batch_size=256, epochs=20, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 3s 51ms/step - loss: 0.3787 - acc: 0.9088\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(raw_test, label_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
